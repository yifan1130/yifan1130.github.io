---
---
@misc{yu2025echolmacceleratingllmserving,
      title={IC-Cache: Efficient Large Language Model Serving via In-context Caching}, 
      author={Yifan Yu* and Yu Gan* and Lillian Tsai and Nikhil Sarda and Jiaming Shen and Yanqi Zhou and Arvind Krishnamurthy and Fan Lai and Henry M. Levy and David Culler},
      year={2025},
      annotation={* Example Contribution},
      selected={true},
      preview={echolm.png},
      award={Acceptance rate: 17 percent},
      award_name={31st SOSP}
      journal={Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
      url={https://arxiv.org/abs/2501.12689}, 
}

@article{li2023loftq,
  title={Loftq: Lora-fine-tuning-aware quantization for large language models},
  author={Li, Yixiao* and Yu, Yifan* and Liang, Chen and He, Pengcheng and Karampatziakis, Nikos and Chen, Weizhu and Zhao, Tuo},
  journal={The Twelfth International Conference on Learning Representations},
  year={2024},
  preview={loftq.png},
  selected={true},
  annotation={* Example Contribution},
  award={About 1 percent of the submissions are selected as oral presentation},
  award_name={Oral Presentation}
}

@inproceedings{li2023losparse,
  title={Losparse: Structured compression of large language models based on low-rank and sparse approximation},
  author={Li, Yixiao* and Yu, Yifan* and Zhang, Qingru and Liang, Chen and He, Pengcheng and Chen, Weizhu and Zhao, Tuo},
  booktitle={International Conference on Machine Learning},
  pages={20336--20350},
  year={2023},
  organization={PMLR},
  annotation={* Example Contribution},
  preview={losparse.png},
  selected={true},
}

