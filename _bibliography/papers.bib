---
---
@misc{yu2025echolmacceleratingllmserving,
      title={EchoLM: Accelerating LLM Serving with Real-time Knowledge Distillation}, 
      author={Yifan Yu* and Yu Gan* and Lily Tasi and Nikhil Sarda and Jiaming Shen and Yanqi Zhou and Arvind Krishnamurthy and Fan Lai and Henry M. Levy and David Culler},
      year={2025},
      annotation={* Example Contribution},
      eprint={2501.12689},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      selected={true},
      preview={echolm.png},
      url={https://arxiv.org/abs/2501.12689}, 
}

@article{li2023loftq,
  title={Loftq: Lora-fine-tuning-aware quantization for large language models},
  author={Li, Yixiao* and Yu, Yifan* and Liang, Chen and He, Pengcheng and Karampatziakis, Nikos and Chen, Weizhu and Zhao, Tuo},
  journal={The Twelfth International Conference on Learning Representations},
  year={2024},
  preview={loftq.png},
  selected={true},
  annotation={* Example Contribution},
  award={About 1 percent of the submissions are selected as oral presentation},
  award_name={Oral Presentation}
}

@inproceedings{li2023losparse,
  title={Losparse: Structured compression of large language models based on low-rank and sparse approximation},
  author={Li, Yixiao* and Yu, Yifan* and Zhang, Qingru and Liang, Chen and He, Pengcheng and Chen, Weizhu and Zhao, Tuo},
  booktitle={International Conference on Machine Learning},
  pages={20336--20350},
  year={2023},
  organization={PMLR},
  annotation={* Example Contribution},
  preview={losparse.png},
  selected={true},
}

